#!/usr/bin/env node

/**
 * Mock Whisper.cpp Server
 * 
 * This is a simple HTTP server that simulates the whisper.cpp server /inference endpoint
 * for testing purposes. It returns realistic mock data without requiring an actual
 * whisper.cpp installation.
 * 
 * Usage:
 *   node project/mock-whisper-server.js [port]
 * 
 * Example:
 *   node project/mock-whisper-server.js 8081
 * 
 * Then configure Obsidian Vox to use: http://127.0.0.1:8081
 */

const http = require('http');
const PORT = process.argv[2] || 8081;

// Mock transcription data - simulates whisper.cpp response
const mockTranscription = {
  task: "transcribe",
  language: "english",
  duration: 19.93137550354004,
  text: "This is a mock transcription generated by the test server. It simulates what whisper.cpp would return for an actual audio file. The transcription includes multiple segments with word-level timestamps and probability scores.",
  segments: [
    {
      id: 0,
      text: " This is a mock transcription generated by the test server.",
      start: 0.0,
      end: 4.5,
      tokens: [314, 761, 284, 651, 17510, 1517, 739, 1630, 416, 262, 1332, 4382],
      words: [
        {
          word: "This",
          start: 0.2,
          end: 0.5,
          t_dtw: -1,
          probability: 0.95
        },
        {
          word: "is",
          start: 0.5,
          end: 0.7,
          t_dtw: -1,
          probability: 0.98
        },
        {
          word: "a",
          start: 0.7,
          end: 0.8,
          t_dtw: -1,
          probability: 0.97
        },
        {
          word: "mock",
          start: 0.8,
          end: 1.2,
          t_dtw: -1,
          probability: 0.92
        },
        {
          word: "transcription",
          start: 1.2,
          end: 2.0,
          t_dtw: -1,
          probability: 0.89
        },
        {
          word: "generated",
          start: 2.0,
          end: 2.6,
          t_dtw: -1,
          probability: 0.91
        },
        {
          word: "by",
          start: 2.6,
          end: 2.8,
          t_dtw: -1,
          probability: 0.96
        },
        {
          word: "the",
          start: 2.8,
          end: 3.0,
          t_dtw: -1,
          probability: 0.98
        },
        {
          word: "test",
          start: 3.0,
          end: 3.4,
          t_dtw: -1,
          probability: 0.93
        },
        {
          word: "server",
          start: 3.4,
          end: 4.5,
          t_dtw: -1,
          probability: 0.94
        }
      ],
      temperature: 0,
      avg_logprob: -0.22993923723697662,
      no_speech_prob: 0.01573946326971054
    },
    {
      id: 1,
      text: " It simulates what whisper.cpp would return for an actual audio file.",
      start: 4.5,
      end: 9.8,
      tokens: [632, 985, 32907, 644, 22765, 13, 20322, 561, 1441, 329, 281, 4036, 6597, 2393],
      words: [
        {
          word: "It",
          start: 4.5,
          end: 4.7,
          t_dtw: -1,
          probability: 0.97
        },
        {
          word: "simulates",
          start: 4.7,
          end: 5.5,
          t_dtw: -1,
          probability: 0.88
        },
        {
          word: "what",
          start: 5.5,
          end: 5.8,
          t_dtw: -1,
          probability: 0.96
        },
        {
          word: "whisper.cpp",
          start: 5.8,
          end: 6.8,
          t_dtw: -1,
          probability: 0.85
        },
        {
          word: "would",
          start: 6.8,
          end: 7.1,
          t_dtw: -1,
          probability: 0.94
        },
        {
          word: "return",
          start: 7.1,
          end: 7.6,
          t_dtw: -1,
          probability: 0.93
        },
        {
          word: "for",
          start: 7.6,
          end: 7.8,
          t_dtw: -1,
          probability: 0.98
        },
        {
          word: "an",
          start: 7.8,
          end: 8.0,
          t_dtw: -1,
          probability: 0.97
        },
        {
          word: "actual",
          start: 8.0,
          end: 8.5,
          t_dtw: -1,
          probability: 0.92
        },
        {
          word: "audio",
          start: 8.5,
          end: 9.0,
          t_dtw: -1,
          probability: 0.95
        },
        {
          word: "file",
          start: 9.0,
          end: 9.8,
          t_dtw: -1,
          probability: 0.96
        }
      ],
      temperature: 0,
      avg_logprob: -0.18567234523423462,
      no_speech_prob: 0.00823946326971054
    },
    {
      id: 2,
      text: " The transcription includes multiple segments with word-level timestamps and probability scores.",
      start: 9.8,
      end: 16.2,
      tokens: [383, 35288, 4909, 3294, 17894, 351, 1573, 12, 5715, 4628, 395, 14885, 8198],
      words: [
        {
          word: "The",
          start: 9.8,
          end: 10.0,
          t_dtw: -1,
          probability: 0.98
        },
        {
          word: "transcription",
          start: 10.0,
          end: 10.9,
          t_dtw: -1,
          probability: 0.91
        },
        {
          word: "includes",
          start: 10.9,
          end: 11.5,
          t_dtw: -1,
          probability: 0.93
        },
        {
          word: "multiple",
          start: 11.5,
          end: 12.2,
          t_dtw: -1,
          probability: 0.94
        },
        {
          word: "segments",
          start: 12.2,
          end: 13.0,
          t_dtw: -1,
          probability: 0.90
        },
        {
          word: "with",
          start: 13.0,
          end: 13.3,
          t_dtw: -1,
          probability: 0.97
        },
        {
          word: "word-level",
          start: 13.3,
          end: 14.1,
          t_dtw: -1,
          probability: 0.87
        },
        {
          word: "timestamps",
          start: 14.1,
          end: 14.9,
          t_dtw: -1,
          probability: 0.89
        },
        {
          word: "and",
          start: 14.9,
          end: 15.1,
          t_dtw: -1,
          probability: 0.98
        },
        {
          word: "probability",
          start: 15.1,
          end: 15.8,
          t_dtw: -1,
          probability: 0.88
        },
        {
          word: "scores",
          start: 15.8,
          end: 16.2,
          t_dtw: -1,
          probability: 0.92
        }
      ],
      temperature: 0,
      avg_logprob: -0.21234523423423462,
      no_speech_prob: 0.00923946326971054
    }
  ],
  detected_language: "english",
  detected_language_probability: 0.98,
  language_probabilities: {
    en: 0.98,
    es: 0.005,
    fr: 0.004,
    de: 0.003,
    it: 0.002,
    pt: 0.002,
    nl: 0.001,
    ru: 0.001,
    zh: 0.001,
    ja: 0.001
  }
};

// Parse multipart form data to extract filename (simple implementation)
function parseMultipartFormData(buffer, boundary) {
  const parts = buffer.toString().split(boundary);
  let filename = 'unknown.mp3';
  
  for (const part of parts) {
    if (part.includes('filename=')) {
      const match = part.match(/filename="([^"]+)"/);
      if (match) {
        filename = match[1];
        break;
      }
    }
  }
  
  return filename;
}

// Create HTTP server
const server = http.createServer((req, res) => {
  // Enable CORS
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  // Handle OPTIONS preflight
  if (req.method === 'OPTIONS') {
    res.writeHead(200);
    res.end();
    return;
  }

  // Handle /inference endpoint
  if (req.url === '/inference' && req.method === 'POST') {
    let body = [];
    
    req.on('data', chunk => {
      body.push(chunk);
    });
    
    req.on('end', () => {
      const buffer = Buffer.concat(body);
      const contentType = req.headers['content-type'] || '';
      
      // Extract boundary from content-type
      const boundaryMatch = contentType.match(/boundary=([^;]+)/);
      const boundary = boundaryMatch ? boundaryMatch[1] : null;
      
      // Parse filename if available
      let filename = 'audio.mp3';
      if (boundary) {
        filename = parseMultipartFormData(buffer, boundary);
      }
      
      // Log the request
      console.log(`[${new Date().toISOString()}] POST /inference`);
      console.log(`  File: ${filename}`);
      console.log(`  Size: ${buffer.length} bytes`);
      
      // Simulate processing delay (100-500ms)
      const delay = Math.random() * 400 + 100;
      
      setTimeout(() => {
        // Return mock transcription
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify(mockTranscription, null, 2));
        console.log(`  Status: 200 OK (${delay.toFixed(0)}ms)`);
      }, delay);
    });
    
    req.on('error', (err) => {
      console.error('Request error:', err);
      res.writeHead(500, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: 'Internal server error' }));
    });
    
  } else {
    // Handle unknown endpoints
    res.writeHead(404, { 'Content-Type': 'application/json' });
    res.end(JSON.stringify({ 
      error: 'Not found',
      message: 'Only /inference endpoint is supported'
    }));
  }
});

// Start server
server.listen(PORT, '127.0.0.1', () => {
  console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘         Mock Whisper.cpp Server for Testing               â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('');
  console.log(`ðŸš€ Server running at: http://127.0.0.1:${PORT}`);
  console.log(`ðŸ“¡ Endpoint: http://127.0.0.1:${PORT}/inference`);
  console.log('');
  console.log('Configuration for Obsidian Vox:');
  console.log(`  1. Enable "Use Self-Hosted Backend"`);
  console.log(`  2. Set backend location to: http://127.0.0.1:${PORT}`);
  console.log('');
  console.log('Test with curl:');
  console.log(`  curl http://127.0.0.1:${PORT}/inference \\`);
  console.log(`    -F file="@test.mp3" \\`);
  console.log(`    -F temperature="0.0" \\`);
  console.log(`    -F temperature_inc="0.2" \\`);
  console.log(`    -F response_format="json"`);
  console.log('');
  console.log('Press Ctrl+C to stop the server');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('');
});

// Handle graceful shutdown
process.on('SIGINT', () => {
  console.log('\n\nðŸ‘‹ Shutting down mock server...');
  server.close(() => {
    console.log('âœ… Server stopped');
    process.exit(0);
  });
});

process.on('SIGTERM', () => {
  console.log('\n\nðŸ‘‹ Shutting down mock server...');
  server.close(() => {
    console.log('âœ… Server stopped');
    process.exit(0);
  });
});
